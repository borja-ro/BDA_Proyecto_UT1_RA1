# üìä Proyecto UT1 ‚Äî Sensores de CO‚ÇÇ (Microbatch con idempotencia)

## 1. Descripci√≥n general
Este pipeline simula lecturas de sensores de CO‚ÇÇ en aulas, realiza la ingesta incremental
en SQLite con trazabilidad e idempotencia, limpia los datos seg√∫n reglas de calidad y
almacena los resultados en formato Parquet particionado.

A continuaci√≥n se muestra la arquitectura general del flujo de datos.

---

### 1.1 Diagrama general del flujo

```mermaid
flowchart TD
    %% ====== SECCI√ìN 1: CONFIGURACI√ìN Y ESTRUCTURA ======
    A1[üß≠ 1. Configuraci√≥n inicial\n - Librer√≠as\n - Par√°metros Pandas\n - Constantes y rutas del proyecto] --> A2[üìÅ Creaci√≥n de estructura de carpetas\n(project/data/output/...)]
    A2 --> A3[üìä Definici√≥n de BANDAS y HORARIO_LECTIVO]

    %% ====== SECCI√ìN 2: GENERACI√ìN DE DATOS ======
    subgraph B[2Ô∏è‚É£ Generaci√≥n / Adquisici√≥n de datos]
        B1[üß© Funci√≥n generar_evento_id()] --> B2[‚öôÔ∏è Funci√≥n simular_lecturas()\n‚Üí crea lecturas.log (NDJSON)\ncon anomal√≠as]
        B2 --> B3[üìÇ Archivo generado:\nproject/data/drops/lecturas.log]
    end
    A3 --> B

    %% ====== SECCI√ìN 3: INGESTA DE DATOS ======
    subgraph C[3Ô∏è‚É£ Ingesta de datos (microbatch)]
        C1[üóÑÔ∏è ensure_db()\n‚Üí crea tablas raw_events, clean_events, quarantine] --> C2[üîÅ upsert_raw()\n‚Üí inserta datos con idempotencia y WAL]
        C2 --> C3[üì• read_new_lines()\n‚Üí lee solo l√≠neas nuevas del log usando checkpoint]
        C3 --> C4[üß© ingest_microbatch()\n‚Üí orquesta lectura + inserci√≥n en raw_events]
        C4 -->|Checkpoint .offset| CKPT[(üìÑ output/checkpoints)]
    end
    B3 --> C

    %% ====== SECCI√ìN 4: LIMPIEZA Y CALIDAD ======
    subgraph D[4Ô∏è‚É£ Limpieza y valoraci√≥n de calidad]
        D1[üßπ clean_and_export()\n‚Üí aplica reglas de validaci√≥n:\n‚Ä¢ out_of_range\n‚Ä¢ missing_aula\n‚Ä¢ out_of_hours\n‚Ä¢ malformed] --> D2[‚úÖ clean_events (v√°lidos)]
        D1 --> D3[üö´ quarantine (inv√°lidos)]
        D1 --> D4[üíæ Exportaci√≥n Parquet:\noutput/parquet/raw\noutput/parquet/clean]
    end
    C4 --> D

    %% ====== SECCI√ìN 5: MANTENIMIENTO ======
    subgraph E[5Ô∏è‚É£ Mantenimiento y control]
        E1[‚ö° √çndices en SQLite\n(ix_raw_ts, ix_clean_ts_aula)] --> E2[üßΩ clear_database()\n‚Üí limpia tablas manteniendo DB]
        E2 --> E3[üß® reset_pipeline()\n‚Üí borra Parquet, checkpoints y ut1.db]
    end
    D --> E

    %% ====== ARCHIVOS DE SALIDA ======
    E --> F[üì¶ output/ut1.db\n(output/parquet/, quality/, checkpoints/)]

    %% ====== ETAPA FINAL ======
    F --> G[üßæ reporte.md\nResumen y visualizaci√≥n final]

    %% VISUAL STYLE
    classDef phase fill:#002b36,stroke:#ffffff,stroke-width:2px,color:#fff;
    class A1,A2,A3,B,C,D,E,F,G phase;
```

---

### 1.2 Versi√≥n horizontal (pipeline ETL)

```mermaid
flowchart LR
    %% ETAPA 1: CONFIGURACI√ìN
    A1([üß≠ Configuraci√≥n inicial\nImports, rutas y par√°metros]) --> 
    A2([üìÅ Estructura de carpetas\nproject/data/output]) --> 

    %% ETAPA 2: GENERACI√ìN
    B1([‚öôÔ∏è Simulaci√≥n NDJSON\n(simular_lecturas ‚Üí lecturas.log)]) --> 

    %% ETAPA 3: INGESTA
    C1([üóÑÔ∏è Ingesta micro-batch\nensure_db + upsert_raw]) --> 
    C2([üß© Checkpoint + idempotencia\n.read_new_lines / .offset]) --> 

    %% ETAPA 4: LIMPIEZA
    D1([üßπ Limpieza y calidad\nclean_and_export ‚Üí reglas:\nout_of_range, out_of_hours, missing_aula]) --> 
    D2([üíæ Exportaci√≥n Parquet\n(raw / clean) + SQLite]) --> 

    %% ETAPA 5: MANTENIMIENTO
    E1([‚ö° √çndices en SQLite\nix_raw_ts / ix_clean_ts_aula]) --> 
    E2([üßΩ clear_database / reset_pipeline]) --> 

    %% ETAPA 6: SALIDA FINAL
    F1([üì¶ Salidas finales:\nut1.db + parquet/ + reporte.md])

    %% STYLE
    classDef block fill:#073642,stroke:#eee,stroke-width:2px,color:#fff,font-size:12px;
    class A1,A2,B1,C1,C2,D1,D2,E1,E2,F1 block;
```

---

## 2. Interpretaci√≥n
El flujo del pipeline sigue una arquitectura **ETL simplificada**, con separaci√≥n clara entre:
- **Ingesta (Bronce):** captaci√≥n incremental y almacenamiento crudo.
- **Limpieza (Plata):** validaci√≥n, deduplicaci√≥n y cuarentena de registros.
- **Almacenamiento / Reporte (Oro):** persistencia en SQLite y Parquet, con generaci√≥n final de KPIs y alertas.

---

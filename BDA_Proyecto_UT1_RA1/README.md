# Proyecto UT1 Â· Sensores de COâ‚‚ (Microâ€‘batch, idempotencia, Parquet/SQLite)

Trabajo prÃ¡ctico de **Sistemas de Big Data**. Pipeline mÃ­nimo que:
1) **Genera** lecturas simuladas (NDJSON) con anomalÃ­as controladas.  
2) **Ingesta** en microâ€‘lotes con **checkpoint** e **idempotencia** (SQLite + WAL).  
3) **Limpia/valida** (rangos, dominios, horario lectivo) y **cuarentena**.  
4) **Persiste** en **Parquet** (raw/clean, particionado) y en **SQLite** (`ut1.db`).  
5) **(Opcional)** Genera **`output/reporte.md`** desde el notebook.

---

## ğŸ—‚ï¸ Estructura del repositorio

```
project/
â”œâ”€ data/
â”‚  â””â”€ drops/                  # AquÃ­ se genera/lee lecturas.log (NDJSON)
â”œâ”€ docs/                      # DocumentaciÃ³n (ingesta, calidad, modelado, lecciones)
â”œâ”€ output/
â”‚  â”œâ”€ parquet/
â”‚  â”‚  â”œâ”€ raw/                 # Parquet de eventos crudos
â”‚  â”‚  â””â”€ clean/               # Parquet de eventos limpios
â”‚  â”œâ”€ quality/                # (opcional) reportes de calidad
â”‚  â”œâ”€ checkpoints/            # Offsets (.offset) para read_new_lines()
â”‚  â”œâ”€ ut1.db                  # SQLite (tablas: raw_events, clean_events, quarantine)
â”‚  â””â”€ reporte.md              # Reporte final en Markdown (opcional)
â”œâ”€ notebooks/
â”‚  â””â”€ master_notebook.ipynb   # Notebook principal: genera â†’ ingesta â†’ limpia â†’ exporta
â””â”€ README.md
```

> âš ï¸ El notebook crea la estructura automÃ¡ticamente si no existe.

---

## âœ… Requisitos

- **Python 3.11+**
- **conda** (Miniforge/Anaconda) para aislar el entorno
- `requirements.txt` (ya incluido; se generÃ³ con `pip freeze > requirements.txt`)

---

## ğŸ§ª PreparaciÃ³n del entorno (Conda + VS Code/Jupyter)

```bash
# 1) Crear y activar entorno
conda create -n ut1_co2 python=3.11 -y
conda activate ut1_co2

# 2) Instalar dependencias del proyecto
pip install -r requirements.txt

# 3) (Opcional) Registrar kernel para Jupyter/VS Code
python -m ipykernel install --user --name ut1_co2 --display-name "Python (ut1_co2)"
```

En **VS Code**: Selecciona el kernel **Python (ut1_co2)** en la barra superior del notebook.

---

## â–¶ï¸ EjecuciÃ³n (desde el notebook)

Abre `project/notebooks/master_notebook.ipynb` y ejecuta, en orden:

1. **ConfiguraciÃ³n:** imports, constantes, bandas de calidad y rutas (crea estructura `project/...`).  
2. **SimulaciÃ³n:** genera `project/data/drops/lecturas.log` (NDJSON) con anomalÃ­as controladas.  
3. **Ingesta (microâ€‘lote):**
   - `ensure_db(DB)` crea tablas en `output/ut1.db`  
   - `read_new_lines()` lee **solo** nuevas lÃ­neas usando `checkpoints/`  
   - `upsert_raw()` inserta con **idempotencia** (`ON CONFLICT(event_id) DO UPDATE ...`)  
4. **Limpieza y calidad:**
   - Valida `co2_ppm` (300â€“5000), `aula` no vacÃ­a, y **horario lectivo** definido
   - VÃ¡lidos â†’ `clean_events` y `parquet/clean/`
   - InvÃ¡lidos â†’ `quarantine` con `cause` y `parquet/raw/` si procede
5. **(Opcional) Reporte:** ejecutar la celda final que escribe `output/reporte.md` (incluye mÃ©tricas y fecha de generaciÃ³n).

> Reâ€‘ejecutar ingesta no duplica datos: **idempotencia** por `event_id` + `_ingest_ts` (â€œÃºltimo ganaâ€).

---

## ğŸ§¾ Reporte (`output/reporte.md`)

Estructura sugerida (adaptada a COâ‚‚):  
- **Titular** (ppm media, nÂº alertas)  
- **KPIs** (vÃ¡lidos, cuarentena, alertas >1500 ppm, aula con mayor variabilidad)  
- **Top aulas** por ppm media  
- **EvoluciÃ³n por hora** (tabla)  
- **Calidad y cobertura** (causas de cuarentena)  
- **Persistencia** (rutas Parquet/SQLite)  
- **Conclusiones** (ventilaciÃ³n/horarios/sensores a revisar)

> Si deseas que el reporte se **genere automÃ¡ticamente**: deja activa la celda final del notebook que lo escribe.

---

## ğŸ§° Comandos Ãºtiles

```bash
# Ver remotos y rama actual (antes de hacer push)
git status
git remote -v

# (Opcional) cambiar remoto al repo personal
git remote set-url origin git@github.com:b0rjen/BDA_Proyecto_UT1_RA1.git

# AÃ±adir/commit/push
git add .
git commit -m "UT1 CO2: simulacion, ingesta, limpieza, parquet y reporte"
git push origin main
```

---

## ğŸ§¹ Mantenimiento / reset

En el notebook tienes dos utilidades:

- `clear_database(DB)`: elimina tablas `raw_events`, `clean_events`, `quarantine` **sin borrar** `ut1.db`.  
- `reset_pipeline()`: borra `output/parquet/`, `output/checkpoints/` y `output/ut1.db` para rehacer todo.

**Nota sobre SQLite (WAL):** al usar `PRAGMA journal_mode=WAL;` se crean `ut1.db-wal` y `ut1.db-shm`.  
SQLite los gestiona automÃ¡ticamente. Si deseas consolidar manualmente:  
```python
import sqlite3
with sqlite3.connect("project/output/ut1.db") as con:
    con.execute("PRAGMA wal_checkpoint(FULL);")
```

---

## ğŸ Problemas frecuentes

- **Permisos al crear carpetas** dentro de Google Drive/Cloud: mueve el proyecto a una ruta local (p. ej. `~/Proyectos/UT1_CO2/`) y vuelve a ejecutar la celda de creaciÃ³n de rutas.  
- **â€œdatabase is lockedâ€**: asegÃºrate de cerrar conexiones (`with sqlite3.connect(...)`) o usa el modo WAL (ya activado en `upsert_raw`).  
- **No se ve Mermaid en `reporte.md` en VS Code**: instala **Markdown Preview Mermaid Support** y encierra el diagrama en bloque ```mermaid.
```

---

## ğŸ“„ Licencia / AutorÃ­a

Trabajo acadÃ©mico de la asignatura **Sistemas de Big Data**.  
Datos simulados con fines docentes.  
Autor: **Borja Ramos (b0rjen)** Â· 2025.
